{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intregrate GooglePalm in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install faiss-cpu PyPDF2 langchain_google_genai langchain  langchain_community python-dotenv pypdf google-cloud-aiplatform>=1.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "api_key = 'AIzaSyBXtQlO-v2h7M5Or9G7cu1bFoYY6xRPY9c' \n",
    "\n",
    "llm = GooglePalm(google_api_key=api_key, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check LLM is worked or Not ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = llm(\"List 5 sri lankan meal plans\")\n",
    "print(foods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all Pdf file name from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "pdf_directory = './food_data/pdf'\n",
    "\n",
    "# Get all file names in the directory\n",
    "pdf_file_names = os.listdir(pdf_directory)\n",
    "pdf_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all pdf file data from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "pdf_loader = PyPDFDirectoryLoader(pdf_directory,extract_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install rapidocr-onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docs = pdf_loader.load_and_split()\n",
    "pdf_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=200\n",
    "        )  ## Chunk Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pdf_documents = (\n",
    "            text_splitter.split_documents(pdf_docs)\n",
    "        )  # splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",google_api_key=api_key\n",
    "        )\n",
    "\n",
    "# from langchain.embeddings import GooglePalmEmbeddings\n",
    "\n",
    "# # Initialize instructor embeddings using the Hugging Face model\n",
    "# google_palm_embeddings = GooglePalmEmbeddings(google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vector_db = FAISS.from_documents(\n",
    "            pdf_docs, google_embeddings\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make retriver for similarity search -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an intelligent chatbot specialized in providing information about various foods. You can answer questions about how to prepare different foods, their nutritional content, potential allergens, and associated diseases. Use the data from the vector database to provide accurate and relevant responses. \n",
    "\n",
    "Given the following context and a question, give an answer based on the asked question.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "\"response\" is most based on context and If the related data are not found in the context, kindly give most approprate answers most matched to context.\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            memory=memory,\n",
    "                            return_source_documents=False,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =  chain.invoke(\"What are the benefits of eating a balanced diet?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =  chain.invoke(\"What We Can Prepare with Sweet Potatoes ?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
