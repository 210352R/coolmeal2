{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import GooglePalm\n",
    "api_key = 'AIzaSyBXtQlO-v2h7M5Or9G7cu1bFoYY6xRPY9c' \n",
    "\n",
    "# llm = GooglePalm(google_api_key=api_key, temperature=0.7)\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crispy crust, a savory treat,\n",
      "Samosa, my heart's ardent beat.\n",
      "Potato and peas, a perfect blend,\n",
      "A taste of heaven, unending end.\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a prompt template for the chatbot\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    template=\"The following is a conversation with a chatbot. The chatbot is helpful, creative, and very friendly. \\n\\nUser: {user_input}\\nChatbot:\"\n",
    ")\n",
    "\n",
    "# Create an LLMChain instance with the prompt template and the LLM\n",
    "llm_chain = LLMChain(prompt=prompt_template, llm=llm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'Who found google ?', 'text': 'Larry Page and Sergey Brin'}\n"
     ]
    }
   ],
   "source": [
    "res =  llm_chain.invoke(\"Who found google ?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What are the nationalities of them ?', 'text': \"I'm not sure what you mean. Can you please rephrase your question?\"}\n"
     ]
    }
   ],
   "source": [
    "res =  llm_chain.invoke(\"What are the nationalities of them ?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.memory == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "pdf_directory = './server/food_data/pdf'\n",
    "\n",
    "# Get all file names in the directory\n",
    "pdf_file_names = os.listdir(pdf_directory)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "pdf_loader = PyPDFDirectoryLoader(pdf_directory,extract_images=True)\n",
    "\n",
    "pdf_docs = pdf_loader.load_and_split()\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=200\n",
    "        )  \n",
    "\n",
    "\n",
    "\n",
    "final_pdf_documents = (\n",
    "            text_splitter.split_documents(pdf_docs)\n",
    "        )  \n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",google_api_key=api_key\n",
    "        )\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vector_db = FAISS.from_documents(\n",
    "            pdf_docs, google_embeddings\n",
    "        )\n",
    "\n",
    "retriever = vector_db.as_retriever(score_threshold = 0.7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=5,memory_key=\"chat_history\",  return_messages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    " You are the specialized AI assistant for a food datas. Give most accurate answer to the following questions, Sometimes given context may be helpful And somtime you may need to use your Knowledge to answer the question. You can get sense from given chat history also\"\n",
    "CONTEXT: {context}\n",
    "QUESTION: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            memory = memory,\n",
    "                            return_source_documents=False,\n",
    "                            chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Sweet potato fries\n",
      "• Mashed sweet potatoes\n",
      "• Baked sweet potatoes\n",
      "• Sweet potato casserole\n",
      "• Sweet potato soup\n",
      "• Sweet potato hash\n",
      "• Sweet potato pie\n"
     ]
    }
   ],
   "source": [
    "res =  chain.invoke(\"What We Can Prepare with Sweet Potatoes ?\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='What We Can Prepare with Sweet Potatoes ?'), AIMessage(content='• Sweet potato fries\\n• Mashed sweet potatoes\\n• Baked sweet potatoes\\n• Sweet potato casserole\\n• Sweet potato soup\\n• Sweet potato hash\\n• Sweet potato pie')]), memory_key='chat_history')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement LLM chain chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an LLMChain instance with the prompt template and the LLM\n",
    "llm_chain = LLMChain(prompt=PROMPT, llm=llm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Sweet potato fries\n",
      "• Mashed sweet potatoes\n",
      "• Baked sweet potatoes\n",
      "• Sweet potato casserole\n",
      "• Sweet potato soup\n",
      "• Sweet potato hash\n",
      "• Sweet potato pie\n"
     ]
    }
   ],
   "source": [
    "question = \"What We Can Prepare with Sweet Potatoes ?\"\n",
    "context =  retriever.get_relevant_documents(\"What We Can Prepare with Sweet Potatoes\")\n",
    "res = llm_chain.invoke({'context': context, 'question': question})\n",
    "print(res['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = \"\"\"\n",
    " You are the specialized AI assistant for a food datas. Give most accurate answer to the following questions, Sometimes given context may be helpful And somtime you may need to use your Knowledge to answer the question. You can get Information from given chat history also\"\n",
    "CONTEXT: {context}\n",
    "QUESTION: {question}\n",
    "CHAT_HISTORY: {chat_history}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\",\"question\" ,\"chat_history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.memory == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention Paneer & Meatball Masala Curry recipe, so I cannot provide you with the ingredients and measurements.\n"
     ]
    }
   ],
   "source": [
    "res =  chain.invoke(\"What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention anything about Paneer, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "res =  chain.invoke(\"Give  Method of preparation of Paneer ?\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context does not mention anything about the capital of India, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "res =  chain.invoke(\"Capital of India\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Custom Memory Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom memory stack (empty at first)\n",
    "custom_memory_stack = [\"Assistant : Hi ! I am specialized AI assistant for a food datas \"]\n",
    "\n",
    "\n",
    "# Stack size limit (if you want to limit the chat history)\n",
    "STACK_SIZE_LIMIT = 3\n",
    "\n",
    "\n",
    "# Function to format memory into a string (join the stack)\n",
    "def format_memory(memory_stack):\n",
    "    return \"\\n\".join(memory_stack)\n",
    "\n",
    "# Function to update the memory stack and maintain stack size\n",
    "def update_memory_stack(question, response, memory_stack, limit=STACK_SIZE_LIMIT):\n",
    "    # Add the new question and response to the stack\n",
    "    memory_stack.append(f\"User: {question}\")\n",
    "    memory_stack.append(f\"Assistant: {response}\")\n",
    "    \n",
    "    # Ensure the stack doesn't exceed the limit\n",
    "    if len(memory_stack) > 2 * limit:  # each interaction is 2 entries (question & response)\n",
    "        memory_stack = memory_stack[-2 * limit:]  # Keep only the last `limit` interactions\n",
    "    \n",
    "    return memory_stack\n",
    "\n",
    "def clear_memory_stack(memory_stack):\n",
    "    memory_stack = [\"Assistant : Hi ! I am specialized AI assistant for a food datas \"]\n",
    "    return memory_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question , custom_memory_stack):\n",
    "     # Pass the query and the formatted memory to the chain\n",
    "    formatted_memory = format_memory(custom_memory_stack)\n",
    "    print(f\"Memory: {formatted_memory}\")\n",
    "    context =  retriever.get_relevant_documents(question)\n",
    "    res = llm_chain.invoke({'context': context, 'question': question , 'chat_history':formatted_memory})\n",
    "    print(res['text'])\n",
    "    # Update the memory stack with the new question and response\n",
    "    custom_memory_stack = update_memory_stack(question, res['text'], custom_memory_stack)\n",
    "    print(custom_memory_stack)\n",
    "    return res['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: Assistant : Hi ! I am specialized AI assistant for a food datas \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.\n",
      "['Assistant : Hi ! I am specialized AI assistant for a food datas ', 'User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?', 'Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?\",custom_memory_stack=custom_memory_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: Assistant : Hi ! I am specialized AI assistant for a food datas \n",
      "User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?\n",
      "Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.\n",
      "This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.\n",
      "['Assistant : Hi ! I am specialized AI assistant for a food datas ', 'User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?', 'Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.', 'User: what method used to cook it ?', 'Assistant: This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"what method used to cook it ?\",custom_memory_stack=custom_memory_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: Assistant : Hi ! I am specialized AI assistant for a food datas \n",
      "User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?\n",
      "Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.\n",
      "User: what method used to cook it ?\n",
      "Assistant: This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.\n",
      "Avocado is a fruit with a single seed and a thick green skin. It is native to Central America and South Mexico. They are high in fat, but it is mostly healthy fat. Avocados are a good source of vitamins C and K, potassium, and fiber.\n",
      "['User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?', 'Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.', 'User: what method used to cook it ?', 'Assistant: This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.', 'User: what is Avacado ?', 'Assistant: Avocado is a fruit with a single seed and a thick green skin. It is native to Central America and South Mexico. They are high in fat, but it is mostly healthy fat. Avocados are a good source of vitamins C and K, potassium, and fiber.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Avocado is a fruit with a single seed and a thick green skin. It is native to Central America and South Mexico. They are high in fat, but it is mostly healthy fat. Avocados are a good source of vitamins C and K, potassium, and fiber.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"what is Avacado ?\",custom_memory_stack=custom_memory_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: Assistant : Hi ! I am specialized AI assistant for a food datas \n",
      "User: What are the ingredients of  Paneer & Meatball Masala Curry and give how much amount of each ingrdient used?\n",
      "Assistant: The provided context does not mention anything about the ingredients of Paneer & Meatball Masala Curry, so I cannot provide the requested information.\n",
      "User: what method used to cook it ?\n",
      "Assistant: This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.\n",
      "User: what is Avacado ?\n",
      "Assistant: Avocado is a fruit with a single seed and a thick green skin. It is native to Central America and South Mexico. They are high in fat, but it is mostly healthy fat. Avocados are a good source of vitamins C and K, potassium, and fiber.\n",
      "- Guacamole\n",
      "- Avocado toast\n",
      "- Avocado smoothie\n",
      "- Avocado salad\n",
      "- Avocado sushi rolls\n",
      "- Avocado pasta\n",
      "- Avocado ice cream\n",
      "['User: what method used to cook it ?', 'Assistant: This context does not mention anything about methods used to cook vegetables, so I cannot answer this question from the provided context.', 'User: what is Avacado ?', 'Assistant: Avocado is a fruit with a single seed and a thick green skin. It is native to Central America and South Mexico. They are high in fat, but it is mostly healthy fat. Avocados are a good source of vitamins C and K, potassium, and fiber.', 'User: what can we prepare from Avacado?', 'Assistant: - Guacamole\\n- Avocado toast\\n- Avocado smoothie\\n- Avocado salad\\n- Avocado sushi rolls\\n- Avocado pasta\\n- Avocado ice cream']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Guacamole\\n- Avocado toast\\n- Avocado smoothie\\n- Avocado salad\\n- Avocado sushi rolls\\n- Avocado pasta\\n- Avocado ice cream'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"what can we prepare from Avacado?\",custom_memory_stack=custom_memory_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
